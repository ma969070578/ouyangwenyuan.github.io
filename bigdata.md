---
title: bigdata
date: 2017-05-02 00:27:35
tags:
---

大数据技术作为决策神器，日益在社会治理和企业管理中起到不容忽视的作用，美国，欧盟都已经将大数据研究和使用列入国家发展的战略，类似谷歌，微软，百度，亚马逊等巨型企业也同样把大数据技术视为生命线以及未来发展的关键筹码。这个系列的教程将从技术和应用的角度解读大数据与云计算里的具体内容，和你一起拔高人生的视野。


大数据是什么？
		首先，大数据技术是什么？ 简而言之，从大数据中提取大价值的挖掘技术。专业的说，就是根据特定目标，从数据收集与存储，数据筛选，算法分析与预测，数据分析结果展示，以辅助作出最正确的抉择，其数据级别通常在PB以上，复杂程度前所未有。      
		关键作用是什么？ 挖掘出各个行业的关键路径，帮助决策，提升社会（或企业）运作效率。      
		最初是在怎样的场景下提出？ 在基础学科经历信息快速发展之后，就诞生了“大数据”的说法。但其实是随着数据指数级的增长，尤其是互联网商业化和传感器移动化之后，从大数据中挖掘出某个事件现在和未来的趋势才真正意义上被大众所接触。      
		大数据技术包含的内容概述？ 非结构化数据收集架构，数据分布式存储集群，数据清洗筛选架构，数据并行分析模拟架构，高级统计预测算法，数据可视化工具。      
		大数据技术的具体内容？ 分布式存储计算架构（强烈推荐：Hadoop） 分布式程序设计（包含：Apache Pig或者Hive） 分布式文件系统（比如：Google GFS） 多种存储模型，主要包含文档，图，键值，时间序列这几种存储模型（比如：BigTable，Apollo， DynamoDB等） 数据收集架构（比如：Kinesis，Kafla） 集成开发环境（比如：R-Studio） 程序开发辅助工具（比如：大量的第三方开发辅助工具） 调度协调架构工具（比如：Apache Aurora） 机器学习（常用的有Apache Mahout 或 H2O） 托管管理（比如：Apache Hadoop Benchmarking） 安全管理（常用的有Gateway） 大数据系统部署（可以看下Apache Ambari） 搜索引擎架构（ 学习或者企业都建议使用Lucene搜索引擎） 多种数据库的演变（MySQL/Memcached） 商业智能（大力推荐：Jaspersoft ） 数据可视化（这个工具就很多了，可以根据实际需要来选择） 大数据处理算法（10大经典算法）  
		大数据中常用的分析技术？ A/B测试、关联规则挖掘、数据聚类、 数据融合和集成、遗传算法、自然语言处理、 神经网络、神经分析、优化、模式识别、 预测模型、回归、情绪分析、信号处理、 空间分析、统计、模拟、时间序列分析  
		大数据未来的应用趋势预测？ 每个人健康和生活都需要的个性化建议； 企业管理中的选择和开拓新市场的可靠信息来源； 社会治理中大众利益的发现与政策满足。  大数据的目的在于挖掘价值，而它的本质与OODA循环决策模型非常相似。用OODA这个原型来理解大数据是最合适的了！在战场上，OODA循环决策的周期越短，胜算越大；在市场中，大数据收集和反馈信息最快，效果越好！



OODA原型
		概而论之，OODA指的是在充分观察了解你和对手的环境的前提下，模拟对手在特定环境下的行为，进而做出一系列的对策，并且快速响应执行！之后又迅速收集反馈信息，进入下一个OODA循环决策。  
		   
		    
		观察: 指的是通过多角度了解你与对手目前的真实处境。要做的事情就是尽可能全面地收集过去和现在的信息。以求足够了解对手正在所使用的策略和战术。  
		    
		调整： 利用观察到的信息来感知和分析对手，并且根据对手的历史信息模拟其后续的决策行为，对目前自己的行为作出最优的调整建议。这一步骤也最为关键！  
		    
		决策： 根据自己的现状，从多种调整方案中筛选权衡出最行之有效的执行方案。这一步其实依赖对己方所有大小情况的掌握。胜利属于作出正确决策的一方！  
		    
		执行： 这个毋庸置疑，没有执行的方案就是一纸空文。这与平时训练养成的素质有关。中国俗语说，“养兵千日，用兵一时。”这个时候就是生死存亡见分晓的时候了。同时也是在校验决策的正确性！  
		    END  
OODA与大数据
		OODA的整个处理流程，其实就是一个运动控制系统。大数据也是类似，从手机信息、处理分析到决策执行，这些都与OODA有异曲同工之妙！大数据的运算速度与OODA的循环速度一样，都提前决定着结果。  
		    
		OODA强调的是根据对手的行为作出决策；大数据的核心是依据分析结果指导策略的制定！而这都严重地依赖对海量环境数据的研究分析，以求找到最佳的应对方案！  
		OODA曾经是只为军事服务。如今这个思想工具已经开始在各个行业中应用开来。这就好比大数据在各行各业中都有不同程度的用武之地，并且逐步发挥关键性的作用！  
		OODA的发明者认为并不一定要按照顺序来完成（观察/调整/决策/执行），允许基于文化和新的经验跳跃式自由组合着使用，同样的，大数据也不能按照固定模式来使用，而是根据具体环境和应用场景来做预测分析的工作！也正因为如此，大数据才前途无量！！    END  
接着前两篇对大数据的介绍之后，本篇从实际操作的角度分享大数据内部关键的运作机制，这是在真正开始学习大数据之前对大数据的一个概览。为的是让我们成为大数据的主人。



大数据运行机制
	.	1 这是对大数据运行机制的概览，如果你阅读过上一篇（OODA），就会感觉非常熟悉。不错，他们在概念上是如出一撤的！不过实际操作却又有巨大的不同。  
	.	    
	.	2 收集数据： 大数据的第一站就是收集和存储海量数据（公开/隐私）。现在每个人都是一个巨大的数据源，通过智能手机和个人笔记本释放出大量的个人行为信息。获取数据似乎已经变得越来越容易，数据收集这一模块最大的挑战在于获取海量数据的高速要求以及数据的全面性考虑。  
	.	    
	.	3 清洗数据：  传统商业智能在数据清洗处理的做法（ETL）是，把准确的数据放入定义好的格式中，通过基础的抽取统计生成高维度的数据，方便直接使用。然而大数据有个最突出的特征——数据非结构化或者半结构化。因为数据有可能是图片，二进制等等。数据清洗的最大挑战来了——如何转化处理大量非结构数据，便于分布式地计算分析。  
	.	    
	.	4 硬件：  这是大家都很熟悉的概念，和大数据相关的是虚拟化。主要包括存储虚拟化，计算虚拟化。因此又说虚拟化存储和云计算是大数据的“左膀右臂”！！大数据还需要支持多种类型的数据库，因此一个支持扩展的数据仓库是大数据中的基础。  
	.	    
	.	5 多平台与多架构并行使用：  大数据处理需要多平台和多架构。这是由大数据的快速响应以及多维度分析所决定的特征。通常大数据会把一个任务拆分成多个极小的子任务交由不同的服务器来并行处理，最终由任务调度系统负责汇总分析计算结果。这也是美国谷歌公司需要用到上百万服务器的原因。  
	.	    
	.	6 机器学习与人类判断：  “一拳难敌众手”，面对似乎处理不完的海量数据，需要机器来帮助我们一起处理。机器学习指的是不断从大数据分析中吸收特征数据，成为我们用来分析数据的关键参考指标！当然很多时候机器学习有可能会被误导，因此需要人类来判断机器学习的结果是否符合预期，以及进一步完善机器学习的结果！！  
	.	    
	.	7 分享与反馈：  随着大数据分析结果的产生，决策者需要的旺旺不是一堆僵硬的数据，而是一张直观动态的决策建议视图。并且在决策之后，需要一个执行反馈系统来评估大数据分析结果的准确性。不断地去优化大数据分析的架构和算法！使得大数据架构更加智能！！  
	.	    
	.	8 最后请你再次阅读这个系列的上一篇文章，对比大数据与OODA之间的异同点，并且在图纸上画出你对大数据的理解！  
Hadoop作为大数据工业中的主引擎，了解Hadoop就像是在打开大数据这扇门。首先它本身是一个分布式计算架构，更重要的是它是一个可扩展的生态系统，像IBM，EMC，Amazon，微软，甲骨文等大型IT公司都已经有了基于Hadoop的商业化大数据产品。虽然现在还有比Hadoop更为先进的分布式架构（Dremel，DataFlow等），但也都是基于Hadoop的改进升级，因此也说Hadoop是大数据的基础，基础的稳固决定了未来能走多远！！



工具/原料
		前置技能：Java编程，数据库技术 
		阅读能力：初级以上的英文阅读水平 
Hadoop是什么
	.	1 Hadoop是一个大家族，是一个开源的生态系统，是一个分布式运行系统，是基于Java编程语言的架构。不过它最高明的技术还是HDFS和MapReduce，使得它可以分布式处理海量数据。  
	.	   
	.	    
	.	2 HDFS（分布式文件系统）： 它与现存的文件系统不同的特性有很多，比如高度容错（即使中途出错，也能继续运行），支持多媒体数据和流媒体数据访问，高效率访问大型数据集合，数据保持严谨一致，部署成本降低，部署效率提交等，如图是HDFS的基础架构  
	.	    
	.	3 MapReduce（并行计算架构）： 它可以将计算任务拆分成大量可以独立运行的子任务，接着并行运算，另外会有一个系统调度的架构负责收集和汇总每个子任务的分析结果。其中 包含映射算法与规约算法。如图是MapReduce的内部计算步骤  
	.	    
	.	4 Pig/Hive（Hadoop编程）： Pig是一种高级编程语言，在处理半结构化数据上拥有非常高的性能，可以帮助我们缩短开发周期。 Hive是数据分析查询工具，尤其在使用类SQL查询分析时显示是极高的性能。可以在分分钟完成ETL要一晚上才能完成的事情，这就是优势，占了先机！  
	.	    
	.	5 HBase/Sqoop/Flume（数据导入与导出）: HBase是运行在HDFS架构上的列存储数据库，并且已经与Pig/Hive很好地集成。通过Java API可以近无缝地使用HBase。 Sqoop设计的目的是方便从传统数据库导入数据到Hadoop数据集合(HDFS/Hive)。 Flume设计的目的是便捷地从日志文件系统直接把数据导到Hadoop数据集合(HDFS)中。 以上这些数据转移工具都极大的方便了使用的人，提高了工作效率，把经历专注在业务分析上！  
	.	    
	.	6 ZooKeeper/Oozie（系统管理架构）： ZooKeeper是一个系统管理协调架构，用于管理分布式架构的基本配置。它提供了很多接口，使得配置管理任务简单化！ Oozie服务是用于管理工作流。用于调度不同工作流，使得每个工作都有始有终。 这些架构帮助我们轻量化地管理大数据分布式计算架构。  
	.	7 Ambari/Whirr（系统部署管理）： Ambari帮助相关人员快捷地部署搭建整个大数据分析架构，并且实时监控系统的运行状况。 Whirr的主要作用是帮助快速的进行云计算开发。  
	.	8 Mahout（机器学习）： Mahout旨在帮助我们快速地完成高智商的系统。其中已经实现了部分机器学习的逻辑。这个架构可以让我们快速地集成更多机器学习的智能！！  END  
Hadoop推荐书籍
	.	1 两本最重要的书籍（这两本基本已经可以满足大部分你对Hadoop的需要）： Hadoop权威指南/Hadoop最佳实践  
	.	    
	.	2 补充书籍资料： Hadoop Operations/Professional Hadoop Solutions/Programing Pig/Programing Hive/Data Science for Business  
	.	3 专业论文： 谷歌关于大数据基础的一些重要论文（GFS / MapReduce）  
	.	    
	.	4 补充Apache网站资料： hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html pig.apache.org/ spark.apache.org aws.amazon.com/dynamodb mahout.apache.org  
	.	  面对如此复杂的大数据架构，各大软硬件服务商都结合自身的特色，参考Hadoop架构，独立研发看家本领，那就一起来领教一下吧。博取大家之所长，对我们日后对架构的设计思路会有很大的启发！



工具/原料
		对Hadoop的了解（阅读本系列前一篇） 
云端的大数据
	.	1 “云”其实指的是多台虚拟服务器的组合，云为不同的使用者提供一个计算的平台。这就是IaaS（基础设置即服务），亚马逊的Amazon EC2和Amazon S3就是这样一个服务。  
	.	    
	.	2 IaaS带给你的是大数据计算的资源，而PaaS将为您提供更为高级的大数据服务。所谓平台即服务（PaaS）指的是提供各种开发解决方案和系统环境。按需使用的PaaS又称为中间件，极大的节省了部署环境的时间和成本。  
	.	    
	.	3 目前主要的大数据服务提供商是Amazon/Microsoft/Google，这些大型的服务商提供IaaS和PaaS的混合服务，以满足不同业务要求。其中Google专注于大数据应用的研究上，Amazon发力提供更多规模的大数据服务平台。  
	.	    END  
大数据服务对比
	.	 不同大数据服务提供商有不同的产品线，因此不同提供商的产品适用场景也会有所不同。我们重点分析三大服务提供商的大数据服务架构。  
	.	    
	.	 亚马逊        拥有大量关于大数据处理的经验。初期大数据使用者大部分都使用亚马逊打造的Hadoop架构服务（EC2）。        经过厚重沉淀之后，Amazon在2009年提供开发EMR大数据服务。EMR服务提供了多种大数据处理分析方案，比如简单查询服务，关联数据分析服务。EMR服务可以使用Hadoop语言继续开发，并且访问EMR服务的步骤也相当简单并且安全。       亚马逊使用托管DynamoDB代替HBase，作为易于扩展的NoSQL数据库。  
	.	    
	.	 谷歌      谷歌云服务平台出类拔萃，它所提供的并非虚拟化解决方案，而是提供由API定义的服务和应用程序。程序员无需顾虑硬件，甚至不需要关心后台的运作行为。       当然这从某种程度也限制了程序员的工作，不过如果谷歌的服务适合业务，那么使用起来将是全世界最高效快捷的大数据架构服务。       谷歌的AppEngine作为云平台管理服务，提供了基于MapReduce的大数据并行计算服务。所有的这些服务都可以通过REST风格的API访问。       BigQuery作为分析的数据库，提供了类SQL的查询语法。它的性能要比Apache Hive来得快！  
	.	    
	.	 微软        微软在大数据中属于后来居上者。通过Microsoft Azure大数据服务平台，微软融合自身海量成熟的软件，例如SQL Server，提供了多种IaaS服务。        微软的服务面向更多的程序员，使得可以使用不同语言来对接大数据平台Azure。Azure旨在提供一个生态的大数据分析开发环境，使得普通研究员也可以施展自己对大数据的理解！  
	.	    
	.	 汇总了Amazon/Microsoft/Google的产品服务，这些产品都已经很稳定地在提供服务。不同的业务对服务架构有不同的要求，收藏这份对比图，Excel文档下载地址：http://pan.baidu.com/s/1qWBJnYW  
	.	 Cetas项目最早起源于VMware公司，PostgreSQL公司和Greenplum公司一起发起的Polaris项目。目的是让大数据分析轻量化，让大数据的福利惠及中小企业，甚至私人服务。Cetas作为开放的PaaS，使得大数据分析更加容易部署，和运行。同时Cetas作为一种新型的服务模式（AaaS）提供服务，AaaS表示分析即服务。其官方文件在这里可以看到：docs.pivotal.io



工具/原料
		对大数据服务比较 的了解（阅读本系列前一篇） 
Cetas项目关注点
	.	1 在线应用分析：       及时乃至实时的决策提供了投资的成功可能性！随着各式各样应用产生不规则的数据产生，这些数据到底想告诉你我什么呢？我们相信大数据将提供一个远见，一个对客户的洞察。那就没有理由去怀疑，基于用户的产品和服务会成功！Cetas提供了一个易于管理，自助服务的虚拟环境，支持企业自定义创建多种应用。这里提供了多维度的行为分析和大量高级的分析算法。  
	.	    
	.	2 IT运营分析：        除了提供在线应用实时的高级分析之外，还能分析IT运营管理，提供企业的管理运营能力。这为企业提供了对企业IT运营效果的面面观。  
	.	    
	.	3 企业Hadoop分析：        为企业或个人提供可扩展，高性能的Hadoop自助分析平台，也提供了可视化的数据发现功能，并且嵌入了大量先进的机器学习算法，这些都促进研究和深度挖掘大数据所隐藏的内容。甚至如果你有建模的需要，这个平台也能满足你！！  
	.	   
	.	    
	.	4 从虚拟化的基础上创建起的这三项服务，分别面向私人，公共，甚至是公私混合。从而Cetas使得大数据分析更加轻量化，这也是VMware公司收购Cetas之后加大投入的方向。  
	.	    
	.	5 如今Cetas加入VMware的大家族，未来将被赋予更重要的角色和作用。这方面也让我们拭目以待VMware这架虚拟化马车驶出的大数据分析之路。  
	.	    END  
Cetas架构分析
	.	 数据层： Cetas系统轻量化部署的设计，使得Cetas系统在部署上有明显优势，可以根据不同业务的需要，选择最低成本的大数据存储层。比如亚马逊的EC2和S3，以及各类云存储服务上。而Cetas的数据抓取服务支持接收多种来源多种格式的数据。  
	.	    
	.	 数据分析层： Cetas将大数据以Hadoop或者HBase的组织方式传送给数据分析中心，由分析中心引导在预设分析算法的处理之后，生成各式各样的观察预测结果。更绝的是，Cetas居然可以支持无预设分析算法的情况自动分析生成结果。Cetas还有一些特点就是，支持批处理，组件独立输入和输出。  
	.	    
	.	 数据展示层： Cetas将数据分析中心的处理结果保存到一个缓存区，便于二次分析以及可视化编辑。企业或者个人可以基于分析结果，根据市场的考虑，将数据分析结果以不同的维度展示，或者根据研究成果，开发出适应市场需求的产品和服务。  
	.	 前文已经介绍过Hadoop是什么，但是关于为什么是Hadoop，Hadoop凭借怎样的本事而成为大数据分析技术的标准基础。我们一起从多个角度来了解下Hadoop的威力，以及和这威力密切相关的一切因素。



工具/原料
		请先阅读本系列的前文《Hadoop是什么》 
Hadoop大背景
	.	1 Hadoop起源： Hadoop有个背景，就是起源于Apache Lucene项目中的一个搜索引擎Nutch。Lucene目前是世界上最好，并且开源的搜索引擎框架和产品。Lucene本身就有非常多好的大数据经验和思路。这为Hadoop预备了巨大能量，使得Hadoop注定是一个伟大的产品。  
	.	    
	.	2 Hadoop命名： 其实是一个孩子给棕黄色大象的命名。Hadoop图标在本系列中也随处可见。Google也是一个这样的例子。这样有一个很好的点就是想到Hadoop，就会想到大数据，而不会是其他。  
	.	    
	.	3 Hadoop目标： Hadoop的出现是为了解决搜索引擎无法接受数以亿计单位的数据量的问题。借助Google分享的GFS和MapReduce成熟理论，Hadoop一跃而出，成功解决了海量数据存储和搜索的架构问题。未来Hadoop将支持更巨大的数据和更智能的数据管理。  
	.	    END  
Hadoop大比较
	.	1 为什么选择Hadoop，而不是其他数据处理架构，比如传统关系型数据库或者其他。Hadoop在我的眼里，更像是在“暴力解锁”，它可以处理每一条数据，乃至每一种可能的设想。Hadoop的巨大贡献在于快速分析大数据所隐藏的事实，这在过去也许需要几天甚至几个月的时间才能完成，而Hadoop很可能只需要几分钟甚至几秒钟的时间就可以很完整地做好！  
	.	    
	.	2 关系型数据库的几个特点使得它无缘大数据分析，当然它也有自己擅长的领域。 （1）磁盘可以存储大量内容，却无法快速存取！并且存储空间的扩展是有限度的。 （2）在更新一小部分数据的同时，会对整张表乃至整个数据库都会产生影响。 （3）要求存储的数据都是结构化的，能处理的数据也都是结构化。  
	.	    
	.	3 网格计算尝试通过多台机器（不同的任务）处理和管理共享文件系统，最终达到大数据计算的目的。这样的尝试以网络带宽的约束而失败告终。因为数据量达到GB级别以上时，网格计算的方法显得力不从心。不过网格计算用在中小型科研实验确实是说一不二的选择！  
	.	    END  
Hadoop大未来
	.	 Hadoop在2008年就已经是顶级的Apache项目，之后被各大互联网巨头挖掘开发并且商业化。如果市场上已经有不少成熟的Hadoop分析产品。这些基于Hadoop的产品有重新给Hadoop注入了新的活动。Hadoop将作为大数据分析的一个起点，使得分析未来可以智能化，使得人工智能更加普遍。  
	.	    
	.	 目前谷歌已经不再使用Hadoop架构（可以解决PB级别的数据），而是使用DataFlow结构在完成EB级别数据的分析，并且是基于对Hadoop架构的升级。这是一个可喜的消息，这不意味着Hadoop已经成为历史，而更说明Hadoop架构和其中思想的巨大潜力！  
	.	    
	.	 基于Hadoop的分析架构越来越多，相应的，大数据对现实世界的分析成果会越来越多。这些才是普通人可以实实在在感受到的大数据。比如购物，学习，健康，旅游等等都会变得更加便捷安全。  
	.	    
	.	 大数据给我们带来许多好处，但同时也产生了不少新问题。比如数据隐私，大数据安全，数据滥用等等。这些都将是需要大家达成共识的下一个议题。  
	.	  MapReduce的厉害之处在于高效完整地处理大数据。这是只有MapReduce架构才能完成的事情！等待让我们荒老，但是速度让我们更有价值！本节介绍的是Hadoop中利器之一MapReduce的工作机制，我们正在进入大数据计算的核心区域。



工具/原料
		多了解点新技术总不是坏事！ 
MapReduce工作机制
	.	1 MapReduce的主体是两个函数Map()和Reduce()，Map负责清洗数据，Reduce负责数据分析并输出最终结果，而且这两个功能之间并非一对一的关系，可以根据具体业务选择匹配关系。  
	.	    
	.	2 Map函数 输入：键值关系的数据队列，键是每段内容开头的偏移量。 处理：从输入中抽取出自定义的关键字段。这个处理过程可以很简单，也可以很复杂。 输出：键值关系的数据队列，通常是保存在硬盘上，而不是HDFS中。因为这个数据集只是个中间过程，计算结束时需要被删除。  
	.	    
	.	3 Reduce函数 输入：Map的输出结果经过MapReduce框架处理之后分发给Reduce函数，因为通常一个Reduce函数需要拿到完整的数据集之后才能开始分析。 处理：这一步的分析处理将是最为艰难和富有价值的环节。根据不同业务指标定义处理函数。 输出：输出自定义的格式文件，并且保存在HDFS上。  
	.	    
	.	4 Combiner函数 输入：Map的输出结果未经过MapReduce框架处理之后直接传送给Combiner函数。 处理：Combiner函数着手做合并归类和排序等处理，经过处理之后，数据集大大缩小。 输出：这时的输出结果才传送给MapReduce架构处理中心。 解决问题：减少带宽传输压力！  
	.	    END  
MapReduce的使用
	.	1 首先要明确完成一个MapReduce最小的任务都包含哪些具体工作！部署Hadoop架构，在HDFS系统上分发要处理的数据集，定义Map和Reduce两个函数，配置相关路径和执行顺序。编译生成处理小包，再由Job分发给不同的服务器处理。最终收集整个输出结果！！  
	.	    
	.	2 部署Hadoop架构这一步骤极其简单，代价不菲。因为它需要N台服务器集群。并且通过Hadoop架构连接起来。  
	.	    
	.	3 由于可能会存在多个Reduce函数的情况，因此Map函数的处理结果将会被克隆复制，并且保存到不同的分区，确保每个Reduce处理的数据集是一样的。  
	.	    
	.	4 MapReduce支持多种语言来表达，Java/Ruby/Python等，另外也有直接支持MapReduce的编程语言：Pig/Hive/Scalding等  
	.	    
	.	5 MapReduce的使用已经基本可以解决大部分超级计算。不过它也有一个不可忽视的前提，就是业务分析任务是可拆解的。但也不用太担心，因为这种事情很少会发生！  
	.	   
   
    
    
   

 


